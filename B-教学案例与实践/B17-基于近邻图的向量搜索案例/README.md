Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可
  

# 基于近邻图的向量搜索
约一年前，微软开源了一种基于近邻图的向量搜索算法[SPTAG](https://github.com/microsoft/SPTAG)，该算法能够在大规模向量中快速搜索最近邻，并应用于[Microsoft Bing](https://bing.com)中。我们将在此案例中介绍该搜索算法。

# 案例介绍
## 使用场景
在过去，传统的搜索引擎往往是通过“关键词”对内容进行检索，但这就要求了用户需要将问题抽象成几个“关键词”，且需要精确描述问题。然而，随着网络信息的爆炸式增长和信息技术的高速发展，工程师们发现用户习惯已经悄然改变：用户搜索的内容越来越长，他们往往期望通过输入一段自然语言甚至一张图片来搜索出他们想要的结果，而不只是通过关键词。网络搜索任务也因此变得更加复杂和多样化了。

为此，我们需要思考如何才能将自然语言或者图片与数据库中的内容匹配，找出最相关的内容呢？为了让计算机认识自然语言、图片等内容，我们需要将其编码成计算机认识的形式，其中，最常见和有效的就是向量了。向量可以是各种形式的内容（如关键词、图片、语音等）在高维空间的表示。将不同形式的内容转化的向量的算法各异，但随着深度学习的发展，我们可以利用深度神经网络将绝大部分的内容（常见的有文本、图片、音频、视频等）映射到高维空间，获取到对应的向量。向量在高维空间的表示是有意义的，我们认为关联性越强的内容在空间上的距离越小或相似度越大。因此，利用向量，我们可以更轻易地找出相关联的内容。

利用向量的表示，我们可以将数据库的内容全部转换成向量，再将用户的搜索输入用同样的算法转换成在同一个空间的向量。此时，搜索引擎的匹配问题就变成了**最近邻问题（Nearest Neighbor）**。我们的任务就是从大规模的向量中找出与输入向量最相近的一组向量。

对于大规模数据，Brute-Force或线性查找的时间复杂度是难以接受的。因此，我们需要合适的算法来提高搜索速度。传统的关键词检索可以通过构建倒排索引（Inverted Index）来提高检索速度，但是我们无法为向量构建这样的索引。对于向量，我们通常是利用树或图（如KD-Tree, HNSW）来构建索引，从而帮助我们在大量的向量中找出最相似的向量。当然，鱼与熊掌不可兼得，速度的提升往往是以牺牲精度为前提的。于是，问题最终变成了**近似最近邻（Approximate Nearest Neighbor, ANN）问题**。

但无论是使用树还是图，它们都有各自的问题，例如，KD-Tree在面对高维度数据时效果显著下降，而使用近邻图则容易陷入局部最优。因此，微软提出了SPTAG，通过结合树和图，在弥补各自的不足的基础上，还做出了一定的优化。SPTAG解决的核心问题其实是上述的ANN问题，因此，我们还可以将SPTAG应用到许多不同的场景，如计算机视觉、模式识别等领域。


# 核心知识点

* KD-Tree (K-Dimensional Tree)
* BKTree (Balanced K-Means Tree)
* KNN Graph (K-Nearest Neighbor Graph)
* RNG (Relative Neighborhood Graph)

# 先修知识
* C++
* 数据结构（包含二叉树、哈希算法、图论等基础知识）


# 推荐学习时长
该案例推荐学习时长为：1.5小时

# 案例详解

## 问题定义
SPTAG解决的问题是如何从大规模的向量中快速找出近似最近邻点（Approximate Nearest Neighbor）。

我们可以将问题定义为：

![](./resource/defineProblem.png)

其中，q为查询向量，x为样本向量，我们可以计算它们的L2或余弦距离，获得两者距离最近的样本。

要实现这个目标，有几种常见的最近邻搜索算法（Nearest Neighbor Search）:
1. 基于哈希的最近邻搜索
   
   利用哈希算法（如LSH），在尽可能保留距离关系的情况下，将样本映射到不同的哈希桶（Bucket）中，这时只需比较同一哈希桶中的点即可。但是该方法的查询性能与哈希函数及样本分布有关，样本可能会聚集在某些哈希桶中，导致对于不同点的查询时延差距较大，稳定性不佳。

2. 空间划分树
   
   空间划分树常用的是KD-Tree，通过递归地选取K维作为结点划分依据，将样本划分成左子树和右子树，最终生成一棵二叉树索引。这类方法通常对于低维度的数据效果比较好（如小于100维），但对于高维数据效果较差。而图片的向量表示通常能够达到1000维甚至更多。

3. 近邻图
   
    通过使样本中所有点连接其近邻点，我们可以构建一张近邻图。再通过使用特定的算法（如HNSW），我们可以在搜索时快速找到与查询点相连的近邻点。但是，我们无法确保我们构建的近邻图是连通图，因此有可能会陷入局部最优。



## SPTAG架构

可见，上述提到的算法都有各自的问题，适用于不同的场景，而SPTAG的核心思路是将树和图结合，从而弥补各自的缺陷，使场景更为通用。

其架构如图：

![](./resource/tree+graph.jpg)

SPTAG分为了Tree部分和Graph部分。Tree部分利用KD-Tree或BKTree实现，Graph部分使用了基于KNN图改进的KNG。在进行搜索时，SPTAG首先会从Tree部分获取“种子”向量，将该种子向量作为Graph中的起始点进一步搜索近邻点。

## Tree部分
Tree部分SPTAG使用了KDTree和BKTree实现。在调用时，可以根据需求选择任意一种。KD-Tree适合低维度的向量，反之，BKTree适合高维度的向量。

### KD-Tree


#### 构建

1. 从方差最大的前5个维度中随机选择一个维度作为划分维度，将其平均值作为划分值，划分出两组子空间
2. 分别对划分的子空间递归以上步骤，直到划分的子空间中只有一个点，然后将其作为叶子结点

详细构建算法可以参考：[KD Tree的原理及Python实现](https://zhuanlan.zhihu.com/p/45346117)

#### 搜索
1. 选择到达叶子结点的路径中的最近邻点，将该点的向量作为后续在图中搜索的“种子”向量。


### BKTree

#### 构建

1. 每次使用平衡Kmeans聚类划分K组子空间
2. 分别对划分的子空间递归以上步骤，直到无法继续划分（所有结点都相同或子空间太小），将叶子结点指向这些数据点。

#### 搜索
1. 使用Best-Frist Search的方式搜索BKTree，选择最小查询距离的结点直到找到叶子结点。将叶子结点的向量作为后续在图中搜索的“种子”向量。

* Best-First Search
  * 把v的近邻点放入优先级队列Q
  * 从队列Q中取出第一个点v
  * 重复以上步骤，直到满足搜索条件

## Graph部分
Graph部分，通过先构建KNN图，再根据RNG Rule移除不符合要求的边，得到RNG。

### KNN图的构建
KNN图是指对于样本数据中的每一个点，将其自身与K个近邻点连接而形成的图。

由于样本数据规模非常大，我们采用了一定的算法构建近似的KNN图，具体算法如下：
1. 随机划分一组子空间
2. 对该子空间内的点，利用Brute-Force方式，构建KNN子图。
3. 重复以上步骤N次。N越大，得到的KNN图越接近真实的KNN图。

![](./resource/partition.png)

每次随机划分一组子空间，会包含部分新的近邻点，而与之前划分的空间重叠的近邻点，可以将两组子空间构建的KNN子图连接成更大的KNN图。因此，划分次数越多，KNN子图越大，直到得到真实的KNN图为止。


* 算法来源：[Scalable k-NN graph construction for visual descriptors. Jing Wang, Jingdong Wang, Gang Zeng, Zhuowen Tu, Rui Gan, Shipeng Li. CVPR 2012.
](http://pages.ucsd.edu/~ztu/publication/cvpr12_knnG.pdf)


### KNG的构建
基于KNN图，我们需要根据RNG Rule删除不符合要求的边。这样做的目的是避免陷入局部最优。

RNG Rule：删除三角形中的最长的边。

对于KNN图，若点a, b, q相互连接，我们要分别计算3点的距离，删除最长的边。例如，图中需删除qb边，因为我们可以通过a从q访问到b。

![](./resource/RNGRule.png)



# SPTAG的使用